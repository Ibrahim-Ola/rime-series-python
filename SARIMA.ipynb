{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24210, 9) (3459, 9) (6918, 9)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_parquet('./data/train.parquet')\n",
    "test_df = pd.read_parquet('./data/test.parquet')\n",
    "val_df = pd.read_parquet('./data/val.parquet')\n",
    "\n",
    "\n",
    "print(train_df.shape, val_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General approach for working with a time series is to:\n",
    "\n",
    "1. Plotting the series; notice trends and seasonality (we have done this in `data_preparation.ipynb`).\n",
    "2. Detrend the time series by removing the seasonality and drift.\n",
    "3. Fit a baseline model and calculate the residual.\n",
    "4. Diagnose the residual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SARIMAX\n",
    "\n",
    "SARIMAX (Seasonal AutoRegressive Integrated Moving Average with eXogenous variables) is an advanced statistical model used for forecasting time series data that incorporates both seasonal and non-seasonal components, as well as external or exogenous variables that could influence the time series. It extends the ARIMA model by adding seasonality (SARIMA) and the ability to model the impact of independent external variables, making it highly versatile and powerful for handling complex forecasting scenarios. SARIMAX can be decomposed into:\n",
    "\n",
    "* S: Seasonal\n",
    "\n",
    "* AR: Autoregressive (p)\n",
    "\n",
    "* I: Integrated (d)\n",
    "\n",
    "* MA: Moving Average (q)\n",
    "\n",
    "* X: Exogeneous variables\n",
    "\n",
    "### Stationarity test\n",
    "\n",
    "Stationarity means that the statistical properties of a time series i.e. mean, variance and covariance do not change over time. Many statistical models require the series to be stationary to make effective and precise predictions. There are two tests commonly used in practice:\n",
    "\n",
    "1. Augmented Dickey Fuller (“ADF”) test.\n",
    "2. Kwiatkowski-Phillips-Schmidt-Shin (“KPSS”) test.\n",
    "\n",
    "### ADF Test\n",
    "\n",
    "ADF test is used to determine the presence of unit root in the series, and hence helps in understanding if the series is stationary or not. The null and alternate hypothesis of this test are:\n",
    "\n",
    "$H_0$: the series has a unit root\n",
    "\n",
    "$H_1$: the series has no unit root\n",
    "\n",
    "If we fail to reject the null hypothesis, this test may provide evidence that the series is non-stationary. \n",
    "\n",
    "\n",
    "### KPSS Test\n",
    "\n",
    "KPSS is another test for checking the stationarity of a time series. The null and alternate hypothesis for the KPSS test are opposite that of the ADF test.\n",
    "\n",
    "$H_0$: the process is trend stationary\n",
    "\n",
    "$H_1$: the series has a unit root (series is not stationary)\n",
    "\n",
    "\n",
    "### Verdict\n",
    "\n",
    "It is always better to apply both the tests, so that it can be ensured that the series is truly stationary. If the two tests contradict (as we will see now). KPSS indicates non-stationarity and ADF indicates stationarity - The series is difference stationary. Differencing is to be used to make series stationary. The differenced series is checked for stationarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ADF test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=for_sarimax[['outcome']]\n",
    "\n",
    "ad_fuller_result = adfuller(target)\n",
    "\n",
    "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
    "print(f'p-value: {ad_fuller_result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_df=pd.concat([train_df, val_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 24210 entries, 2006-12-16 18:00:00 to 2009-09-20 11:00:00\n",
      "Data columns (total 9 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Global_active_power    24210 non-null  float64\n",
      " 1   Global_reactive_power  24210 non-null  float64\n",
      " 2   Voltage                24210 non-null  float64\n",
      " 3   Global_intensity       24210 non-null  float64\n",
      " 4   Sub_metering_1         24210 non-null  float64\n",
      " 5   Sub_metering_2         24210 non-null  float64\n",
      " 6   Sub_metering_3         24210 non-null  float64\n",
      " 7   day_sin                24210 non-null  float64\n",
      " 8   day_cos                24210 non-null  float64\n",
      "dtypes: float64(9)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "val_df.index = pd.DatetimeIndex(val_df.index).to_period('H')\n",
    "\n",
    "full_train_df=pd.concat([train_df, val_df])\n",
    "\n",
    "full_train_df.drop(columns=['day_sin', 'day_cos'], inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
